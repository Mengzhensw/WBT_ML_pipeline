{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7687d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Perceptron, SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from BorutaShap import BorutaShap\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from xgboost import XGBClassifier  \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"xgboost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30404d3a",
   "metadata": {},
   "source": [
    "# all DEGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6909af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "df_train = pd.read_csv('data/df_train.txt', sep='\\t')\n",
    "df_test = pd.read_csv('data/df_test.txt', sep='\\t')\n",
    "with open('data/train_deg_ml_list.json', 'r') as file:\n",
    "    total_degs_disease = json.load(file)\n",
    "\n",
    "## delete red blood cell\n",
    "genes_to_remove = {'HBA1', 'HBB', 'HBA2'}\n",
    "\n",
    "for key in total_degs_disease:\n",
    "    total_degs_disease[key] = [\n",
    "        gene for gene in total_degs_disease[key]\n",
    "        if gene not in genes_to_remove\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d3ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disease_train = {}\n",
    "for key in total_degs_disease.keys():\n",
    "    filtered_df = df_train[['ID','disease_code_level2']+total_degs_disease[key]]\n",
    "    filtered_df['disease_code_level2'] = filtered_df['disease_code_level2'].apply(lambda x: 1 if x == key else 0)\n",
    "    filtered_df.set_index('ID', inplace=True)\n",
    "    df_disease_train[key] = filtered_df\n",
    "    \n",
    "df_disease_test = {}\n",
    "for key in total_degs_disease.keys():\n",
    "    filtered_df = df_test[['ID','disease_code_level2']+total_degs_disease[key]]\n",
    "    filtered_df['disease_code_level2'] = filtered_df['disease_code_level2'].apply(lambda x: 1 if x == key else 0)\n",
    "    filtered_df.set_index('ID', inplace=True)\n",
    "    df_disease_test[key] = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd04b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using all genes\n",
    "ml_res_all_genes = {}\n",
    "cv = StratifiedKFold(shuffle=True, random_state=RANDOM_STATE, n_splits=5)\n",
    "\n",
    "\n",
    "for disease in df_disease_train.keys():\n",
    "    x_train, y_train = df_disease_train[disease].iloc[:,1:].values, np.array(df_disease_train[disease]['disease_code_level2'].astype(int))\n",
    "    x_test, y_test = df_disease_test[disease].iloc[:,1:].values, np.array(df_disease_test[disease]['disease_code_level2'].astype(int))\n",
    "    \n",
    "    pipeline = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                           ( \"XGBoost\", XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=RANDOM_STATE))])\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    y_predictions = pipeline.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_predictions)\n",
    "    f1_scores = f1_score(y_test, y_predictions, average='weighted')\n",
    "    ml_res_all_genes[disease] = {'accuracy': accuracy, 'f1_score': f1_scores}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83bf1e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CTRL': {'accuracy': 0.9387755102040817, 'f1_score': 0.9292882599550562},\n",
       " 'AS': {'accuracy': 0.978021978021978, 'f1_score': 0.9761824353241999},\n",
       " 'PS': {'accuracy': 0.9262166405023547, 'f1_score': 0.9126950990715589},\n",
       " 'CAD': {'accuracy': 0.978021978021978, 'f1_score': 0.975189295156562},\n",
       " 'RA': {'accuracy': 0.9623233908948194, 'f1_score': 0.9546353347360721},\n",
       " 'BC': {'accuracy': 0.9858712715855573, 'f1_score': 0.9850738267203158},\n",
       " 'DM': {'accuracy': 0.9497645211930926, 'f1_score': 0.9315368586033093},\n",
       " 'EP': {'accuracy': 0.978021978021978, 'f1_score': 0.973696478959637},\n",
       " 'GBS': {'accuracy': 0.989010989010989, 'f1_score': 0.9855449380389998},\n",
       " 'PCOS': {'accuracy': 0.9686028257456829, 'f1_score': 0.9583894898548092},\n",
       " 'SCZ': {'accuracy': 0.989010989010989, 'f1_score': 0.9855449380389998},\n",
       " 'CC': {'accuracy': 0.9937205651491365, 'f1_score': 0.993207326007326},\n",
       " 'SEP': {'accuracy': 0.989010989010989, 'f1_score': 0.9877246988180747},\n",
       " 'BD': {'accuracy': 0.9858712715855573, 'f1_score': 0.9788571676770434},\n",
       " 'ET': {'accuracy': 0.9811616954474097, 'f1_score': 0.9718321072181159},\n",
       " 'LUC': {'accuracy': 0.9905808477237049, 'f1_score': 0.9893189877215436},\n",
       " 'DI': {'accuracy': 0.9984301412872841, 'f1_score': 0.9983845934187886},\n",
       " 'COPD': {'accuracy': 0.9968602825745683, 'f1_score': 0.9966011273459768},\n",
       " 'PHD': {'accuracy': 0.9858712715855573, 'f1_score': 0.9821818942374085},\n",
       " 'ARF': {'accuracy': 0.9921507064364207, 'f1_score': 0.9913132083917194},\n",
       " 'LIC': {'accuracy': 0.9921507064364207, 'f1_score': 0.9910896704245874},\n",
       " 'MVP': {'accuracy': 0.978021978021978, 'f1_score': 0.9717347985347985},\n",
       " 'SP': {'accuracy': 0.9921507064364207, 'f1_score': 0.9899858595510769},\n",
       " 'LONG': {'accuracy': 0.978021978021978, 'f1_score': 0.9758183317785968},\n",
       " 'CHD': {'accuracy': 0.9607535321821036, 'f1_score': 0.9575216017840972},\n",
       " 'IGM': {'accuracy': 0.978021978021978, 'f1_score': 0.9685288876465348},\n",
       " 'HA': {'accuracy': 0.9560439560439561, 'f1_score': 0.9467686561804209}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_res_all_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99571d41",
   "metadata": {},
   "source": [
    "# shap calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c55638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json    \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "shap_top10 = {}\n",
    "shap_top100 = {}\n",
    "\n",
    "for disease in df_disease_train.keys():\n",
    "    X_shap = df_disease_train[disease].drop(['disease_code_level2'],axis = 1)\n",
    "    y_shap = df_disease_train[disease]['disease_code_level2']\n",
    "    y_shap = y_shap.astype(int)\n",
    "\n",
    "    model = xgboost.XGBRegressor().fit(X_shap, y_shap)\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer(X_shap)\n",
    "    \n",
    "    \n",
    "    ## retrieve value\n",
    "    feature_names = X_shap.columns\n",
    "    mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "    features_with_shap = [(feature, float(value)) for feature, value in zip(feature_names, mean_abs_shap)]\n",
    "    sorted_features = sorted(features_with_shap, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    top_10_features = [feature for feature, _ in sorted_features[:10]]\n",
    "    shap_top10[disease] = top_10_features\n",
    "    top_100_features = [feature for feature, _ in sorted_features[:100]]\n",
    "    shap_top100[disease] = top_10_features\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d313aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/shap_top10.json', 'w') as json_file:\n",
    "    json.dump(shap_top10, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aebeff5",
   "metadata": {},
   "source": [
    "# shap 10 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11122d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disease_train_shap10 = {}\n",
    "for key in df_disease_train.keys():\n",
    "    df_disease_train_shap10[key] = df_disease_train[key][['disease_code_level2']+shap_top10[key]]\n",
    "\n",
    "df_disease_test_shap10 = {}\n",
    "for key in df_disease_test.keys():\n",
    "    df_disease_test_shap10[key] = df_disease_test[key][['disease_code_level2']+shap_top10[key]]\n",
    "\n",
    "\n",
    "ml_res_shap10_genes = {}\n",
    "\n",
    "for disease in df_disease_train_shap10.keys():\n",
    "    x_train, y_train = df_disease_train_shap10[disease].iloc[:,1:].values, np.array(df_disease_train_shap10[disease]['disease_code_level2'].astype(int))\n",
    "    x_test, y_test = df_disease_test_shap10[disease].iloc[:,1:].values, np.array(df_disease_test_shap10[disease]['disease_code_level2'].astype(int))\n",
    "    \n",
    "    pipeline = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                           ( \"XGBoost\", XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=RANDOM_STATE))])\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    y_predictions = pipeline.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_predictions)\n",
    "    f1_scores = f1_score(y_test, y_predictions, average='weighted')\n",
    "    ml_res_shap10_genes[disease] = {'accuracy': accuracy, 'f1_score': f1_scores}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d2a3a",
   "metadata": {},
   "source": [
    "# shap 100 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "572c927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disease_train_shap100 = {}\n",
    "for key in df_disease_train.keys():\n",
    "    df_disease_train_shap100[key] = df_disease_train[key][['disease_code_level2']+shap_top100[key]]\n",
    "\n",
    "df_disease_test_shap100 = {}\n",
    "for key in df_disease_test.keys():\n",
    "    df_disease_test_shap100[key] = df_disease_test[key][['disease_code_level2']+shap_top100[key]]\n",
    "\n",
    "\n",
    "ml_res_shap100_genes = {}\n",
    "\n",
    "for disease in df_disease_train_shap10.keys():\n",
    "    x_train, y_train = df_disease_train_shap100[disease].iloc[:,1:].values, np.array(df_disease_train_shap100[disease]['disease_code_level2'].astype(int))\n",
    "    x_test, y_test = df_disease_test_shap100[disease].iloc[:,1:].values, np.array(df_disease_test_shap100[disease]['disease_code_level2'].astype(int))\n",
    "    \n",
    "    pipeline = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                           ( \"XGBoost\", XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=RANDOM_STATE))])\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    y_predictions = pipeline.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_predictions)\n",
    "    f1_scores = f1_score(y_test, y_predictions, average='weighted')\n",
    "    ml_res_shap100_genes[disease] = {'accuracy': accuracy, 'f1_score': f1_scores}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10df845",
   "metadata": {},
   "source": [
    "# multi class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d03d3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n"
     ]
    }
   ],
   "source": [
    "shap_gene = set(gene for genes in shap_top10.values() for gene in genes)\n",
    "print(len(shap_gene))\n",
    "\n",
    "Disease_list = total_degs_disease.keys()\n",
    "disease_mapping = {disease: i for i, disease in enumerate(Disease_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecebc51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = df_train[list(shap_gene)].values, np.array([disease_mapping[disease] for disease in df_train['disease_code_level2'].tolist()], dtype=int)\n",
    "x_test, y_test = df_test[list(shap_gene)].values, np.array([disease_mapping[disease] for disease in df_test['disease_code_level2'].tolist()], dtype=int)\n",
    "\n",
    "# oversample\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE\n",
    "\n",
    "# SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_resampled_smote, y_resampled_smote = sm.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bd8bb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-neighbours scored 0.8833656443667566 during cross-validation\n",
      "Decision tree scored 0.8079151438105832 during cross-validation\n",
      "Random forest scored 0.9459404629482494 during cross-validation\n",
      "Extremely random forest scored 0.9440982043540442 during cross-validation\n",
      "Adaboost scored 0.07384501297738229 during cross-validation\n",
      "Bagging scored 0.904762434450977 during cross-validation\n",
      "MLP scored 0.943869378674718 during cross-validation\n",
      "SVM (polynomial) scored 0.868183696170348 during cross-validation\n",
      "XGBoost scored 0.9475517771068382 during cross-validation\n",
      "\n",
      "Best classifier: XGBoost with a score of 0.9475517771068382\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegressionCV, RidgeClassifierCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier  \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    \"K-neighbours\": KNeighborsClassifier(),\n",
    "    \"Decision tree\": DecisionTreeClassifier(),\n",
    "    \"Random forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Extremely random forest\": ExtraTreesClassifier(random_state=RANDOM_STATE),\n",
    "    \"Adaboost\": AdaBoostClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(random_state=RANDOM_STATE),\n",
    "    \"MLP\": MLPClassifier(max_iter=2000, hidden_layer_sizes=(20, 20)),\n",
    "    \"SVM (polynomial)\": SVC(kernel=\"poly\",probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "clf_best = None\n",
    "clf_name_best = \"\"\n",
    "score_best = 0\n",
    "\n",
    "cv = StratifiedKFold(shuffle=True, random_state=RANDOM_STATE, n_splits=10)\n",
    "\n",
    "# Separate features\n",
    "#categorical_columns = [0]  \n",
    "numerical_columns = list(range(0, x_train.shape[1])) \n",
    "\n",
    "# Iterate through the classifiers\n",
    "for clf_name, clf in classifiers.items():\n",
    "    \n",
    "    # Preprocessing for numerical and categorical data\n",
    "    #categorical_transformer = Pipeline(steps=[\n",
    "    #    ('encoder', OrdinalEncoder())\n",
    "    #])\n",
    "    \n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numerical_transformer, numerical_columns),\n",
    "       # ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # Calculate cross-validation score\n",
    "    cv_score = np.mean(cross_val_score(pipeline, X_resampled_smote, y_resampled_smote, cv=cv))\n",
    "\n",
    "    print(f\"{clf_name} scored {cv_score} during cross-validation\")\n",
    "    \n",
    "    # Check if the current classifier is the best\n",
    "    if cv_score > score_best:\n",
    "        score_best = cv_score\n",
    "        clf_best = pipeline\n",
    "        clf_name_best = clf_name\n",
    "\n",
    "print(f\"\\nBest classifier: {clf_name_best} with a score of {score_best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0d231",
   "metadata": {},
   "source": [
    "## xgbboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1b739a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "Best accuracy: 0.9629625509825731\n",
      "Best Params: {'XGBoost__colsample_bytree': 0.672894435115225, 'XGBoost__learning_rate': 0.08553614103176525, 'XGBoost__max_depth': 4, 'XGBoost__n_estimators': 359, 'XGBoost__subsample': 0.6739417822102108}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "cv = StratifiedKFold(shuffle=True, random_state=RANDOM_STATE, n_splits=10)\n",
    "\n",
    "numerical_columns = list(range(0, x_train.shape[1])) \n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_columns)\n",
    "])\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ( 'XGBoost', XGBClassifier(eval_metric='logloss', random_state=RANDOM_STATE))])\n",
    "\n",
    "params = {\n",
    "    'XGBoost__n_estimators': randint(100, 400),              \n",
    "    'XGBoost__max_depth': randint(3, 8),                      \n",
    "    'XGBoost__learning_rate': uniform(0.01, 0.1),            \n",
    "    'XGBoost__subsample': uniform(0.6, 0.4),               \n",
    "    'XGBoost__colsample_bytree': uniform(0.6, 0.4)          \n",
    "}\n",
    "\n",
    "XGBoost_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=params,\n",
    "    n_iter=50,\n",
    "    scoring='accuracy',  \n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "XGBoost_search.fit(X_resampled_smote, y_resampled_smote)\n",
    "\n",
    "print(\"Best accuracy:\", XGBoost_search.best_score_)\n",
    "print(\"Best Params:\", XGBoost_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3986d954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.9629625509825731\n",
      "Best Params: {'XGBoost__colsample_bytree': 0.672894435115225, 'XGBoost__learning_rate': 0.08553614103176525, 'XGBoost__max_depth': 4, 'XGBoost__n_estimators': 359, 'XGBoost__subsample': 0.6739417822102108}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best accuracy:\", XGBoost_search.best_score_)\n",
    "print(\"Best Params:\", XGBoost_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3020fc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7880690737833596\n",
      "F1: 0.7876740484295508\n",
      "Balanced Accuracy: 0.7946681871062012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.81        69\n",
      "           1       0.84      0.78      0.81        27\n",
      "           2       0.84      0.72      0.78        65\n",
      "           3       0.83      0.88      0.85        33\n",
      "           4       0.72      0.67      0.69        27\n",
      "           5       0.93      0.85      0.89        33\n",
      "           6       0.71      0.71      0.71        35\n",
      "           7       0.67      0.71      0.69        14\n",
      "           8       0.53      0.89      0.67         9\n",
      "           9       0.75      0.72      0.73        25\n",
      "          10       1.00      0.89      0.94         9\n",
      "          11       0.71      0.86      0.77        14\n",
      "          12       0.61      0.85      0.71        13\n",
      "          13       0.67      0.44      0.53         9\n",
      "          14       0.86      0.50      0.63        12\n",
      "          15       0.93      0.93      0.93        14\n",
      "          16       1.00      1.00      1.00         9\n",
      "          17       1.00      1.00      1.00         7\n",
      "          18       0.83      0.77      0.80        13\n",
      "          19       0.86      0.86      0.86        14\n",
      "          20       0.75      0.86      0.80         7\n",
      "          21       0.88      0.74      0.80        19\n",
      "          22       0.78      1.00      0.88         7\n",
      "          23       0.85      0.85      0.85        40\n",
      "          24       0.81      0.84      0.83        62\n",
      "          25       0.75      0.60      0.67        15\n",
      "          26       0.62      0.69      0.66        36\n",
      "\n",
      "    accuracy                           0.79       637\n",
      "   macro avg       0.80      0.79      0.79       637\n",
      "weighted avg       0.80      0.79      0.79       637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = XGBoost_search.best_estimator_\n",
    "y_pred = best_model.predict(x_test)\n",
    "y_proba = best_model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report,balanced_accuracy_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
